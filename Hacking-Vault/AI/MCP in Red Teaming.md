When testing AI Agents or LLM-integrated pipelines, follow theÂ **Model Context Protocol**:

1. **Instruction Layer**: What instructions control the model?
2. **Context Layer**: What background documents, memories, tools are present?
3. **Input Layer**: What user query or prompt is used?
4. **Output Layer**: What actions or responses are triggered?
5. **Execution Layer**: Does the output trigger tools, plugins, or code execution?

> Testing at each layer ensures granular identification of trust boundaries and isolation failures.

#### ğŸš€ - A
---
1. A
2. B
3. C

---
#### ğŸ“¦ - B
--- 

#### ğŸ–Šï¸ - C


âš  Alert 1
âš  Alert 2
âš  Alert 3


--- 

 1ï¸âƒ£ A
 2ï¸âƒ£ B
 
--- 

â—C


### Properties
---
ğŸ“† created   {{15-08-2025}} 20:45
ğŸ·ï¸ tags: #offensiveaisecurity #ai

---
