These are entry points that an adversary can target:

#### ğŸš€ - Prompt Interfaces
---
- Web UIs, chatbots, CLI agents
- Vulnerable toÂ [[Prompt Injection]],Â _[[Context Overflow]]_,Â _[[AI Jailbreaks]]_ 
---
#### ğŸ“¦ - Plugins and Tools
--- 
- LLM-activated browser, code execution, file access tools
- Vulnerable toÂ _[[Toolchain Abuse]]_,Â _[[AI Arbitrary File Execution]]_,Â _[[AI Credential Exfiltration]]_
#### ğŸ–Šï¸ - Contextual Memory session state
---
- Vector embedding, history files, external memory (e.g., Redis)
- Vulnerable toÂ _[[Persistent Poisoning]]_,Â _[[Vector Clustering Attacks]]_
#### ğŸš€ - Retrieval Augmented Generation
---
- Search systems, internal KBs
- Attack surface includesÂ _[[Knowledge Base Poisoning]]_,Â _[[Embedding Attacks]]_,Â _[[Prompt-Data Injection]]_
---
#### ğŸ“¦ - Model API's and Agents
--- 
- Exposed OpenAI, Anthropic, HuggingFace, or custom endpoints
- Vulnerable toÂ _[[Rate-Based Extraction]]_,Â _[[Jailbreak-as-a-Service]]_,Â _[[Billing Abuse]]_
#### ğŸ–Šï¸ - Training and Fine Tunning Pipelines
- Data preprocessing, prompt datasets, labeling systems
- Vulnerable toÂ _[[Training Data Poisoning]]_,Â _[[AI Backdoor Injection]]_,Â _[[LoRA Vector Hijacking]]_


### Properties
---
ğŸ“† created   {{15-08-2025}} 19:42
ğŸ·ï¸ tags: #offensiveaisecurity #ai

---
