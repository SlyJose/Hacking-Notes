
| Stage                     | Offensive Mapping                                                  |
| ------------------------- | ------------------------------------------------------------------ |
| **[[AI Reconnaissance]]** | Identifying exposed inference APIs, open model endpoints           |
| **[[AI Weaponization]]**  | Crafting adversarial samples or prompt injections                  |
| **[[AI Delivery]]**       | Via user queries, poisoned data uploads, API requests              |
| **[[AI Exploitation]]**   | Triggering logic corruption, model evasion                         |
| **[[AI Exfiltration]]**   | Extracting model predictions, membership data, or stealing weights |
| **[[AI Impact]]**         | Misclassification, denial of AI-based services, reputational loss  |

#### üñäÔ∏è Tools and Frameworks for Understanding ML Attacks

| Tool                                     | Description                                                | Use Case                     |
| ---------------------------------------- | ---------------------------------------------------------- | ---------------------------- |
| **CleverHans**                           | TensorFlow/PyTorch library for adversarial attack crafting | Evasion testing              |
| **Foolbox**                              | Python toolkit for white-box and black-box attacks         | Robustness validation        |
| **ART (Adversarial Robustness Toolbox)** | IBM's security-focused ML toolkit                          | Poisoning, inference attacks |
| **Tramer's KnockoffNets**                | Academic codebase for model theft simulations              | Model extraction             |
| **PromptInject & Gauntlet**              | Tools for prompt injection testing                         | LLM adversarial inputs       |

#### üìî B


####  üìó C


#### ‚ö† Opsec




### Properties
---
üìÜ created   {{12-08-2025}} 15:05
üè∑Ô∏è tags: #offensiveaisecurity #ai

---

